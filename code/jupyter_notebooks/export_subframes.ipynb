{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"export_subframes.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOB4ljirr/lwScSJKJp9cMY"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AfC7bg5fYTN0"},"source":["# Mount to your Drive\r\n","Note that annotations and images must be in your drive."]},{"cell_type":"code","metadata":{"id":"w8RJ7TVEYRzH"},"source":["# Connection to Google Drive\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k2p9aVaOYe7t"},"source":["# Classes and function to get subframes"]},{"cell_type":"code","metadata":{"id":"bevcQDdUY69I"},"source":["# Install required package\r\n","! pip install -U git+https://github.com/albu/albumentations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_epdbLGYENz"},"source":["import os\r\n","from PIL import Image\r\n","from albumentations import Compose, BboxParams, Crop\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib.patches as patches\r\n","import math\r\n","import numpy as np\r\n","import torch\r\n","import torchvision\r\n","from torch.utils.data import Dataset\r\n","import json\r\n","import time\r\n","import datetime\r\n","from datetime import date\r\n","import csv\r\n","\r\n","class Subframes(object):\r\n","    ''' \r\n","    Class allowing the visualisation and the cropping of a labeled \r\n","    image (bbox) into sub-frames whose dimensions are specified \r\n","    by the user.\r\n","\r\n","    Attributes\r\n","    -----------\r\n","    img_name : str\r\n","        name of the image (with extension, e.g. \"My_image.JPG\").\r\n","    image : PIL\r\n","        PIL image.\r\n","    target : dict\r\n","        Must have 'boxes' and 'labels' keys at least.\r\n","        'boxes' must be a list in the 'coco' bounding box format :\r\n","        [[xmin, ymin, width, height], ...]\r\n","    width : int\r\n","        width of the sub-frames\r\n","    height : int\r\n","        height of the sub-frames\r\n","    strict : bool\r\n","        set to True get sub-frames of exact same size \r\n","        (e.g width x height) (default: False)\r\n","    \r\n","    Methods\r\n","    --------\r\n","    getlist(overlap=False)\r\n","        Produces a results list containing, for each row :\r\n","        the sub-frame (3D list, dtype=uint8), the bboxes (2D list),\r\n","        the labels (1D list) and the filename (str).\r\n","    visualise(results)\r\n","        Displays ordered sub-frames of the entire image.\r\n","    topoints(results)\r\n","        Converts the bounding boxes into points annotations.\r\n","    displayobjects(results, points_results, ann_type='point')\r\n","        Displays only sub-frames containing objects.\r\n","    save(results, output_path, object_only=True)\r\n","        Saves sub-frames to a specific path.\r\n","    '''\r\n","\r\n","    def __init__(self, img_name, image, target, width, height, strict=False):\r\n","        '''\r\n","        Parameters\r\n","        -----------\r\n","        img_name : str\r\n","            name of the image (with extension, e.g. \"My_image.JPG\")\r\n","        image : PIL\r\n","            PIL image\r\n","        target : dict\r\n","            Must have 'boxes' and 'labels' keys at least.\r\n","        width : int\r\n","            width of the sub-frames\r\n","        height : int\r\n","            height of the sub-frames\r\n","        strict : bool\r\n","            set to True get sub-frames of exact same size \r\n","            (e.g width x height) (default: False)\r\n","        '''\r\n","\r\n","        self.img_name = img_name\r\n","        self.image = image\r\n","        self.target = target\r\n","        self.width = width\r\n","        self.height = height\r\n","        self.strict = strict\r\n","\r\n","        self.img_width = image.size[0]\r\n","        self.img_height = image.size[1]\r\n","\r\n","        self.x_sub = 1 + int((self.img_width - (self.img_width % width)) / width)\r\n","        self.y_sub = 1 + int((self.img_height - (self.img_height % height)) / height)\r\n","\r\n","    def getlist(self, overlap=False):\r\n","        '''\r\n","        Produces a results list containing, for each row :\r\n","        the sub-frame (3D list, dtype=uint8), the bboxes (2D list),\r\n","        the labels (1D list) and the filename (str).\r\n","        Parameters\r\n","        -----------\r\n","        overlap : bool, optional\r\n","            Set to True to get an overlap of 50% between \r\n","            2 sub-frames (default: False)\r\n","        Returns\r\n","        --------\r\n","        list\r\n","        '''\r\n","        height = self.height\r\n","        width = self.width\r\n","        img_height = self.img_height\r\n","        img_width = self.img_width\r\n","\r\n","        results = []\r\n","\r\n","        # Image preprocessing      \r\n","        image_np = np.array(self.image)\r\n","        boxes = self.target['boxes']\r\n","        labels = self.target['labels']\r\n","        annotations = {'image':image_np,'bboxes':boxes,'labels':labels}\r\n","\r\n","        # Crop lists\r\n","        if overlap is True:\r\n","            overlap = 0.5\r\n","            y_sub = int(np.round(height*overlap))\r\n","            x_sub = int(np.round(width*overlap))\r\n","            rg_ymax = img_height-y_sub\r\n","            rg_xmax = img_width-x_sub\r\n","        else:\r\n","            y_sub = height\r\n","            x_sub = width\r\n","            rg_ymax = img_height\r\n","            rg_xmax = img_width\r\n","\r\n","        crops = []\r\n","\r\n","        for y in range(0, rg_ymax, y_sub):\r\n","            if  y+height <= img_height:\r\n","                for x in range(0, rg_xmax, x_sub):\r\n","                    if  x+width <= img_width:\r\n","                        xmin, ymin = x, y\r\n","                        xmax, ymax = x+width, y+height\r\n","                    elif x+img_width%width <= img_width:\r\n","                        xmin, ymin = img_width - width, y\r\n","                        xmax, ymax = x+img_width%width, y+height\r\n","\r\n","                    if self.strict is True:\r\n","                        crops.append([xmin, ymin, xmax, ymax])\r\n","                    else:\r\n","                        crops.append([x, y, xmax, ymax])\r\n","            \r\n","            elif  y+img_height%height <= img_height:\r\n","                for x in range(0, rg_xmax, x_sub):\r\n","                    if  x+width <= img_width:\r\n","                        xmin, ymin = x, img_height - height\r\n","                        xmax, ymax = x+width, y+img_height%height\r\n","                    elif x+img_width%width <= img_width:\r\n","                        xmin, ymin = img_width - width, img_height - height\r\n","                        xmax, ymax = x+img_width%width, y+img_height%height\r\n","\r\n","                    if self.strict is True:\r\n","                        crops.append([xmin, ymin, xmax, ymax])\r\n","                    else:\r\n","                        crops.append([x, y, xmax, ymax])\r\n","\r\n","        sub = 0\r\n","        for xmin, ymin, xmax, ymax in crops:\r\n","            transf = Compose([Crop(xmin, ymin, xmax, ymax, p=1.0)], \r\n","                                bbox_params=BboxParams(format='coco',\r\n","                                                        min_visibility=0.25, \r\n","                                                        label_fields=['labels']))\r\n","            augmented  = transf(**annotations)\r\n","            sub_name = self.img_name.rsplit('.')[0] + \"_S\" + str(sub) + \".JPG\"\r\n","            results.append([augmented['image'],augmented['bboxes'],augmented['labels'],sub_name])\r\n","            sub += 1\r\n","\r\n","        return results\r\n","\r\n","    def visualise(self, results):\r\n","        '''\r\n","        Displays ordered sub-frames of the entire image.\r\n","        Parameters\r\n","        -----------\r\n","        results : list\r\n","            The list obtained by the method getlist().\r\n","        Returns\r\n","        --------\r\n","        matplotlib plot\r\n","        '''\r\n","\r\n","        if len(results) > (self.x_sub*self.y_sub):\r\n","            x_sub = 2*self.x_sub - 2\r\n","            y_sub = 2*self.y_sub - 2\r\n","        else:\r\n","            x_sub = self.x_sub\r\n","            y_sub = self.y_sub\r\n","\r\n","        plt.figure(1)\r\n","        plt.suptitle(self.img_name)\r\n","        sub = 1\r\n","        for line in range(len(results)):\r\n","\r\n","            if self.img_width % self.width != 0:\r\n","                n_col = x_sub\r\n","                n_row = y_sub\r\n","            else:\r\n","                n_col = x_sub - 1\r\n","                n_row = y_sub - 1\r\n","\r\n","            plt.subplot(n_row, n_col, sub, xlim=(0,self.width), ylim=(self.height,0))\r\n","            plt.imshow(Image.fromarray(results[line][0]))\r\n","            plt.axis('off')\r\n","            plt.subplots_adjust(wspace=0.1,hspace=0.1)\r\n","\r\n","            text_x = np.shape(results[line][0])[1]\r\n","            text_y = np.shape(results[line][0])[0]\r\n","\r\n","            if self.width > self.height:\r\n","                f = self.height*(self.y_sub/y_sub)\r\n","            else:\r\n","                f = self.width*(self.x_sub/x_sub)\r\n","\r\n","            plt.text(0.5*text_x, 0.5*text_y, \r\n","                    \"S\"+str(line),\r\n","                    horizontalalignment='center',\r\n","                    verticalalignment='center',\r\n","                    fontsize=0.02*f,\r\n","                    color='w')\r\n","            sub += 1\r\n","\r\n","    def topoints(self, results):\r\n","        '''\r\n","        Converts the bounding boxes into points annotations.\r\n","        Parameters\r\n","        -----------\r\n","        results : list\r\n","            The list obtained by the method getlist().\r\n","        Returns\r\n","        --------\r\n","        list\r\n","            A 2D list with headers : \"id\", \"filename\", \"count\",\r\n","            \"locations\" where\r\n","            - \"id\" represents the unique id of the sub-frame within \r\n","              the image\r\n","            - \"filename\" is the name of the sub-frame \r\n","              (e.g. \"My_image_S1.JPG\")\r\n","            - \"count\" is the number of objects into the sub-frame\r\n","            - \"points\" is a list of tuple representing the \r\n","              locations of the objects (y,x)\r\n","    \r\n","        '''\r\n","\r\n","        points_results = [['id','filename','count','locations']]\r\n","        loc = []\r\n","        for line in range(len(results)):\r\n","            # Verify that bbox exists\r\n","            if results[line][1]:\r\n","                count = len(results[line][1])\r\n","                for bbox in range(len(results[line][1])):\r\n","                    boxe = results[line][1][bbox]\r\n","                    x = int(boxe[0]+(boxe[2])/2)\r\n","                    y = int(boxe[1]+(boxe[3])/2)\r\n","                    point = (y,x)\r\n","                    loc.append(point)\r\n","            \r\n","                sub_name = self.img_name.rsplit('.')[0] + \"_S\" + str(line) + \".JPG\"\r\n","                points_results.append([line, sub_name, count, loc])\r\n","                loc = []\r\n","\r\n","        return points_results\r\n","\r\n","    def displayobjects(self, results, points_results, ann_type='point'):\r\n","        '''\r\n","        Displays only sub-frames containing objects.\r\n","        Parameters\r\n","        -----------\r\n","        results : list\r\n","            The list obtained by the method getlist().\r\n","        points_results : list\r\n","            The list obtained by the method topoints(results).\r\n","        ann_type : str, optional\r\n","            A string used to specify the annotation type. Choose\r\n","            between :\r\n","            - 'point' to visualise points\r\n","            - 'bbox' to visualise bounding boxes\r\n","            - 'both' to visualise both\r\n","            (default is 'point')\r\n","        Returns\r\n","        --------\r\n","        matplotlib plot\r\n","        '''\r\n","\r\n","        sub_r = 0\r\n","        sub_c = 0\r\n","\r\n","        n_row = int(np.round(math.sqrt(len(points_results)-1)))\r\n","        n_col = n_row\r\n","\r\n","        if int(len(points_results)-1) > int(n_row*n_col):\r\n","            n_row += 1\r\n","\r\n","        fig, ax = plt.subplots(nrows=n_row, ncols=n_col, squeeze=False)\r\n","\r\n","        for r in range(n_row):\r\n","            for c in range(n_col):\r\n","                ax[r,c].axis('off')\r\n","                plt.subplots_adjust(wspace=0.1,hspace=0.1)\r\n","\r\n","        for o in range(1,len(points_results)):\r\n","\r\n","            id_object = points_results[o][0]\r\n","            patch_object = results[id_object][0]\r\n","\r\n","            text_x = np.shape(results[id_object][0])[1]\r\n","            text_y = np.shape(results[id_object][0])[0]\r\n","\r\n","            # Plot\r\n","            ax[sub_r,sub_c].imshow(Image.fromarray(patch_object))\r\n","            ax[sub_r,sub_c].text(0.5*text_x, 0.5*text_y, \r\n","                    \"S\"+str(id_object),\r\n","                    horizontalalignment='center',\r\n","                    verticalalignment='center',\r\n","                    fontsize=15,\r\n","                    color='w',\r\n","                    alpha=0.6)\r\n","\r\n","            if ann_type == 'point':\r\n","                points = points_results[o][3]\r\n","                for p in range(len(points)):\r\n","                    ax[sub_r,sub_c].scatter(points[p][1],points[p][0], color='r')\r\n","            \r\n","            elif ann_type == 'bbox':\r\n","                bboxes = results[id_object][1]\r\n","                for b in range(len(bboxes)):\r\n","                    rect = patches.Rectangle((bboxes[b][0],bboxes[b][1]),bboxes[b][2],bboxes[b][3], linewidth=1, edgecolor='r', facecolor='none')\r\n","                    ax[sub_r,sub_c].add_patch(rect)\r\n","                \r\n","            elif ann_type == 'both':\r\n","                points = points_results[o][3]\r\n","                bboxes = results[id_object][1]\r\n","                for b in range(len(bboxes)):\r\n","                    ax[sub_r,sub_c].scatter(points[b][1],points[b][0], color='b')\r\n","                    rect = patches.Rectangle((bboxes[b][0],bboxes[b][1]),bboxes[b][2],bboxes[b][3], linewidth=1, edgecolor='r', facecolor='none')\r\n","                    ax[sub_r,sub_c].add_patch(rect)\r\n","\r\n","            else:\r\n","                raise ValueError('Annotation of type \\'{}\\' unsupported. Choose between \\'point\\',\\'bbox\\' or \\'both\\'.'.format(ann_type))\r\n","                \r\n","            if sub_c < n_col-1:\r\n","                sub_r = sub_r\r\n","                sub_c += 1\r\n","            else:\r\n","                sub_c = 0\r\n","                sub_r += 1\r\n","            \r\n","    def save(self, results, output_path, object_only=True):\r\n","        '''\r\n","        Saves sub-frames (.JPG) to a specific path.\r\n","        Parameters\r\n","        -----------\r\n","        results : list\r\n","            The list obtained by the method getlist().\r\n","        output_path : str\r\n","            The path to the folder chosen to save sub-frames.\r\n","        object_only : bool, optional\r\n","            A flag used to choose between :\r\n","            - saving all the sub-frames of the entire image\r\n","              (set to False)\r\n","            - saving only sub-frames with objects\r\n","              (set to True, default)\r\n","        Returns\r\n","        --------\r\n","        None\r\n","        '''\r\n","\r\n","        for line in range(len(results)):\r\n","            if object_only is True:\r\n","                if results[line][1]:\r\n","                    subframe = Image.fromarray(results[line][0])\r\n","                    sub_name =  results[line][3]\r\n","                    subframe.save(os.path.join(output_path, sub_name))\r\n","                    \r\n","            elif object_only is not True:\r\n","                subframe = Image.fromarray(results[line][0])\r\n","                sub_name =  results[line][3]\r\n","                subframe.save(os.path.join(output_path, sub_name))\r\n","\r\n","class CustomDataset(Dataset):\r\n","\r\n","    def __init__(self, img_root, ann_root, target_type='coco', transforms=None):\r\n","\r\n","        self.img_root = img_root\r\n","        self.ann_root = ann_root\r\n","        self.target_type = target_type\r\n","        self.transforms = transforms\r\n","\r\n","        with open(ann_root) as json_file:\r\n","            self.data = json.load(json_file)\r\n","\r\n","    def __getitem__(self, idx):\r\n","\r\n","        image_name = self.data['images'][idx]['file_name']\r\n","        image_id = self.data['images'][idx]['id']\r\n","\r\n","        img_path = os.path.join(self.img_root,image_name)\r\n","\r\n","        img = Image.open(img_path).convert(\"RGB\")\r\n","\r\n","        target = {}\r\n","\r\n","        boxes = []\r\n","        area = []\r\n","        labels = []\r\n","\r\n","        for ann in range(len(self.data['annotations'])):\r\n","\r\n","            if self.data['annotations'][ann]['image_id']== image_id:\r\n","\r\n","                if self.target_type == 'coco':\r\n","                    boxes.append(self.data['annotations'][ann]['bbox'])\r\n","\r\n","                elif self.target_type == 'pascal':\r\n","                    bndbox = self.data['annotations'][ann]['bbox']\r\n","                    xmin = bndbox[0]\r\n","                    ymin = bndbox[1]\r\n","                    xmax = bndbox[0] + bndbox[2]\r\n","                    ymax = bndbox[1] + bndbox[3]\r\n","                    boxes.append([xmin,ymin,xmax,ymax])\r\n","\r\n","                labels.append(self.data['annotations'][ann]['category_id'])\r\n","                area.append(self.data['annotations'][ann]['area'])\r\n","\r\n","        target[\"boxes\"] = boxes\r\n","        target[\"labels\"] = labels\r\n","        target[\"image_id\"] = image_id\r\n","        target[\"area\"] = area\r\n","\r\n","        return img, target\r\n","\r\n","    def __len__(self):\r\n","        return len(self.data['images'])\r\n","\r\n","def subexport(img_root, ann_root, width, height, output_folder, \r\n","            overlap=False, strict=False ,pr_rate=50, \r\n","            object_only=True, export_ann=True):\r\n","    '''\r\n","    Function that exports sub-frames created on the basis of \r\n","    images loaded by a dataloader, and their associated new \r\n","    annotations.\r\n","\r\n","    This function uses the 'subframes' class for image processing.\r\n","\r\n","    Parameters\r\n","    -----------\r\n","    img_root : str\r\n","        Path to images.\r\n","\r\n","    ann_root : str\r\n","        Path to a coco-style dict (.json) containing annotations of \r\n","        the initial dataset.\r\n","\r\n","    width : int\r\n","        Width of the sub-frames.\r\n","    \r\n","    height : int\r\n","        Height of the sub-frames.\r\n","    \r\n","    output_folder : str\r\n","        Output folder path where to save sub-frames and new annotations.\r\n","    \r\n","    overlap : bool, optional\r\n","        Set to True to get an overlap of 50% between \r\n","        2 sub-frames (default: False)\r\n","    \r\n","    strict : bool, optional\r\n","        Set to True get sub-frames of exact same size \r\n","        (e.g width x height) (default: False)\r\n","\r\n","    pr_rate : int, optional\r\n","        Console print rate of image processing progress.\r\n","        Default : 50\r\n","    \r\n","    object_only : bool, optional\r\n","        A flag used to choose between :\r\n","            - saving all the sub-frames of the entire image\r\n","            (set to False)\r\n","            - saving only sub-frames with objects\r\n","            (set to True, default)\r\n","\r\n","    export_ann : bool, optional\r\n","        A flag used to choose between :\r\n","            - not exporting annotations with sub-frames\r\n","            (set to False)\r\n","            - exporting annotations with sub-frames\r\n","            (set to True, default\r\n","   \r\n","    Returns\r\n","    --------\r\n","    list\r\n","\r\n","    a coco-type JSON file named 'coco_subframes.json'\r\n","    is created inside the subframes' folder\r\n","    \r\n","    '''\r\n","\r\n","    # Get annos\r\n","    with open(ann_root) as json_file:\r\n","        coco_dic = json.load(json_file)\r\n","\r\n","    # Dataset\r\n","    dataset = CustomDataset(img_root, ann_root, target_type='coco')\r\n","\r\n","    # Sampler\r\n","    sampler = torch.utils.data.SequentialSampler(dataset)\r\n","\r\n","    # Collate_fn\r\n","    def collate_fn(batch):\r\n","        return tuple(zip(*batch))\r\n","\r\n","    # Dataloader\r\n","    dataloader = torch.utils.data.DataLoader(dataset, \r\n","                                            batch_size=1,\r\n","                                            sampler=sampler,\r\n","                                            num_workers=0,\r\n","                                            collate_fn=collate_fn)\r\n","\r\n","    # Header\r\n","    all_results = [['filename','boxes','labels','HxW']]\r\n","\r\n","    # intial time\r\n","    t_i = time.time()\r\n","\r\n","    for i, (image, target) in enumerate(dataloader):\r\n","\r\n","        if i == 0:\r\n","            print(' ')\r\n","            print('-'*38)\r\n","            print('Sub-frames creation started...')\r\n","            print('-'*38)\r\n","\r\n","        elif i == len(dataloader)-1:\r\n","            print('-'*38)\r\n","            print('Sub-frames creation finished!')\r\n","            print('-'*38)\r\n","\r\n","        image = image[0]\r\n","        target = target[0]\r\n","\r\n","        # image id and name\r\n","        img_id = int(target['image_id'])\r\n","        for im in coco_dic['images']:\r\n","            if im['id'] == img_id:\r\n","                img_name = im['file_name']\r\n","\r\n","        # Get subframes\r\n","        sub_frames = Subframes(img_name, image, target, width, height, strict=strict)\r\n","        results = sub_frames.getlist(overlap=overlap)\r\n","\r\n","        # Save\r\n","        sub_frames.save(results, output_path=output_folder, object_only=object_only)\r\n","        \r\n","        if object_only is True:\r\n","            for b in range(len(results)):\r\n","                if results[b][1]:\r\n","                    h = np.shape(results[b][0])[0]\r\n","                    w = np.shape(results[b][0])[1]\r\n","                    all_results.append([results[b][3],results[b][1],results[b][2],[h,w]])\r\n","\r\n","        elif object_only is not True:\r\n","            for b in range(len(results)):\r\n","                h = np.shape(results[b][0])[0]\r\n","                w = np.shape(results[b][0])[1]\r\n","                all_results.append([results[b][3],results[b][1],results[b][2],[h,w]])\r\n","\r\n","        if i % pr_rate == 0:\r\n","            print('Image [{:<4}/{:<4}] done.'.format(i, len(coco_dic['images'])))\r\n","\r\n","    # final time\r\n","    t_f = time.time()\r\n","\r\n","    print('Elapsed time : {}'.format(str(datetime.timedelta(seconds=int(np.round(t_f-t_i))))))\r\n","    print('-'*38)\r\n","    print(' ')\r\n","\r\n","    return_var = np.array(all_results)[:,:3].tolist()\r\n","\r\n","    # Export new annos\r\n","    if export_ann is True:\r\n","        file_name = 'coco_subframes.json'\r\n","        output_f = os.path.join(output_folder, file_name)\r\n","\r\n","        # Initializations\r\n","        images = []\r\n","        annotations = []\r\n","        id_img = 0\r\n","        id_ann = 0\r\n","\r\n","        for i in range(1,len(all_results)):\r\n","            \r\n","            id_img += 1\r\n","\r\n","            h = all_results[i][3][0]\r\n","            w = all_results[i][3][1]\r\n","\r\n","            dico_img = {\r\n","                \"license\": 1,\r\n","                \"file_name\": all_results[i][0],\r\n","                \"coco_url\": \"None\",\r\n","                \"height\": h,\r\n","                \"width\": w,\r\n","                \"date_captured\": \"None\",\r\n","                \"flickr_url\": \"None\",\r\n","                \"id\": id_img\r\n","            }\r\n","\r\n","            images.append(dico_img)\r\n","\r\n","            # Bounding boxes\r\n","            if all_results[i][1]:\r\n","                \r\n","                bndboxes = all_results[i][1]\r\n","\r\n","                for b in range(len(bndboxes)):\r\n","\r\n","                    id_ann += 1\r\n","\r\n","                    bndbox = bndboxes[b]\r\n","                    \r\n","                    # Convert \r\n","                    x_min = int(np.round(bndbox[0]))\r\n","                    y_min = int(np.round(bndbox[1]))\r\n","                    box_w = int(np.round(bndbox[2]))\r\n","                    box_h = int(np.round(bndbox[3]))\r\n","\r\n","                    coco_box = [x_min,y_min,box_w,box_h]\r\n","\r\n","                    # Area\r\n","                    area = box_w*box_h\r\n","\r\n","                    # Label\r\n","                    label_id = all_results[i][2][b]\r\n","\r\n","                    # Store the values into a dict\r\n","                    dico_ann = {\r\n","                            \"segmentation\": [[]],\r\n","                            \"area\": area,\r\n","                            \"iscrowd\": 0,\r\n","                            \"image_id\": id_img,\r\n","                            \"bbox\": coco_box,\r\n","                            \"category_id\": label_id,\r\n","                            \"id\": id_ann\r\n","                    }\r\n","\r\n","                    annotations.append(dico_ann)\r\n","        \r\n","        # Update info\r\n","        coco_dic['info']['date_created'] = str(date.today())\r\n","        coco_dic['info']['year'] = str(date.today().year)\r\n","\r\n","        new_dic = {\r\n","            'info': coco_dic['info'],\r\n","            'licenses': coco_dic['licenses'],\r\n","            'images': images,\r\n","            'annotations': annotations,\r\n","            'categories': coco_dic['categories']\r\n","        }\r\n","\r\n","        # Export json file\r\n","        with open(output_f, 'w') as outputfile:\r\n","            json.dump(new_dic, outputfile)\r\n","\r\n","        if os.path.isfile(output_f) is True:\r\n","            print('File \\'{}\\' correctly saved at \\'{}\\'.'.format(file_name, output_folder))\r\n","            print(' ')\r\n","        else:\r\n","            print('An error occurs, file \\'{}\\' not found at \\'{}\\'.'.format(file_name, output_folder))\r\n","\r\n","    return return_var\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N1y24x1YdLy1"},"source":["# Export sub-frames\n","We used \n","* `~/ground_truth/general_dataset/json/big_size/train_big_size_A_B_E_K_WH_WB.json` for training's sub-frames.\n","\n","* `~/ground_truth/general_dataset/json/big_size/val_big_size_A_B_E_K_WH_WB.json` for validation's sub-frames (for using evaluation tools of mmdetection), with `object_only = False`.\n","\n","* `~/ground_truth/general_dataset/json/big_size/test_big_size_A_B_E_K_WH_WB.json` for test's sub-frames (for using evaluation tools of mmdetection), with `object_only = False`.\n","\n","You can find theses subframes in `mmdetection/data/mammals`.\n"]},{"cell_type":"code","metadata":{"id":"zmkW32kTdODm"},"source":["# Fill in with your paths\r\n","images_folder = '< your specific path here >'\r\n","annos_path = '< your JSON annotations file path here >'\r\n","output_folder = '< your specific path here >'\r\n","\r\n","# Export\r\n","json_dic = subexport(\r\n","        img_root = images_folder,\r\n","        ann_root = annos_path,\r\n","        width = 2000,\r\n","        height = 2000,\r\n","        output_folder = output_folder,\r\n","        strict = True,\r\n","        object_only = True\r\n","    )"],"execution_count":null,"outputs":[]}]}