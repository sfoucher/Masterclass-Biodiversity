{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **General information**"]},{"cell_type":"markdown","metadata":{},"source":["The purpose of this script is to set up the directories for the general dataset that will be used throughout the process of creating the detection model."]},{"cell_type":"markdown","metadata":{},"source":["### **Step #01 - Importing relevant Python libraries**"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from utils.Subframes import Subframes, subexport"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #02 - Creating directories to save the sub-frames**"]},{"cell_type":"markdown","metadata":{},"source":["A total of three new directories will be created for the training, validation and testing dataset. "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["!mkdir -p /general_dataset/sub_frames_500/train\n","!mkdir -p /general_dataset/sub_frames_500/val\n","!mkdir -p /general_dataset/sub_frames_500/test"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #03 - Creating the variables used to create the directories for the dataset**"]},{"cell_type":"markdown","metadata":{},"source":["The variables that need to be created are the following:\n","- Directories for the original unsliced training, validation and testing images ;\n","- Directories for the original unsliced training, validation and testing images' annotations ;\n","- File for the original unsliced training, validation and testing images' annotations ;\n","- The sub-frame's width and height."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["train_images_directory = \"/general_dataset/train\"\n","train_annotations_file = \"/general_dataset/groundtruth/json/big_size/train_big_size_A_B_E_K_WH_WB.json\"\n","train_subframes_directory = \"/general_dataset/sub_frames_500/train\"\n","\n","val_images_directory = \"/general_dataset/val\"\n","val_annotations_file = \"/general_dataset/groundtruth/json/big_size/val_big_size_A_B_E_K_WH_WB.json\"\n","val_subframes_directory = \"/general_dataset/sub_frames_500/val\"\n","\n","test_images_directory = \"/general_dataset/test\"\n","test_annotations_file = \"/general_dataset/groundtruth/json/big_size/test_big_size_A_B_E_K_WH_WB.json\"\n","test_subframes_directory = \"/general_dataset/sub_frames_500/test\"\n","\n","subframe_width = 500\n","subframe_height = 500"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #04 - Creating the sub-frames for the training dataset**"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------\n","Starting creation of the sub-frames...\n","--------------------------------------\n","Image [0   /928 ] done.\n","Image [50  /928 ] done.\n","Image [100 /928 ] done.\n","Image [150 /928 ] done.\n","Image [200 /928 ] done.\n","Image [250 /928 ] done.\n","Image [300 /928 ] done.\n","Image [350 /928 ] done.\n","Image [400 /928 ] done.\n","Image [450 /928 ] done.\n","Image [500 /928 ] done.\n","Image [550 /928 ] done.\n","Image [600 /928 ] done.\n","Image [650 /928 ] done.\n","Image [700 /928 ] done.\n","Image [750 /928 ] done.\n","Image [800 /928 ] done.\n","Image [850 /928 ] done.\n","Image [900 /928 ] done.\n","------------------------------------\n","Finished creation of the sub-frames.\n","------------------------------------\n","--------------------------------------\n","Elapsed time : 0:10:55\n","--------------------------------------\n","\n"]},{"name":"stderr","output_type":"stream","text":["/CRIM_notebooks/jupyter_notebooks/utils/Subframes.py:686: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  return_var = np.array(all_results)[:,:3].tolist()\n"]},{"name":"stdout","output_type":"stream","text":["File 'coco_subframes.json' correctly saved at '/general_dataset/sub_frames_500/train'.\n","\n"]}],"source":["# Creating subframes from the images stored in the training dataset.\n","json_dic = subexport(\n","        img_dir = train_images_directory,\n","        img_anno_path = train_annotations_file,\n","        sfm_width = subframe_width,\n","        sfm_height = subframe_height,\n","        sfm_output_dir = train_subframes_directory,\n","        sfm_overlap = False,\n","        sfm_strict = True,\n","        print_rate = 50,\n","        sfm_object_only = True,\n","        sfm_anno_export = True\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #05 - Creating the sub-frames for the validation dataset**"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------\n","Starting creation of the sub-frames...\n","--------------------------------------\n","Image [0   /111 ] done.\n","Image [50  /111 ] done.\n","Image [100 /111 ] done.\n","------------------------------------\n","Finished creation of the sub-frames.\n","------------------------------------\n","--------------------------------------\n","Elapsed time : 0:03:24\n","--------------------------------------\n","\n","File 'coco_subframes.json' correctly saved at '/general_dataset/sub_frames_500/val'.\n","\n"]}],"source":["# Creating subframes from the images stored in the validation dataset.\n","json_dic = subexport(\n","        img_dir = val_images_directory,\n","        img_anno_path = val_annotations_file,\n","        sfm_width = subframe_width,\n","        sfm_height = subframe_height,\n","        sfm_output_dir = val_subframes_directory,\n","        sfm_overlap = False,\n","        sfm_strict = True,\n","        print_rate = 50,\n","        sfm_object_only = False,\n","        sfm_anno_export = True\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #06 - Creating the sub-frames for the testing dataset**"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------\n","Starting creation of the sub-frames...\n","--------------------------------------\n","Image [0   /258 ] done.\n","Image [50  /258 ] done.\n","Image [100 /258 ] done.\n","Image [150 /258 ] done.\n","Image [200 /258 ] done.\n","Image [250 /258 ] done.\n","------------------------------------\n","Finished creation of the sub-frames.\n","------------------------------------\n","--------------------------------------\n","Elapsed time : 0:07:30\n","--------------------------------------\n","\n","File 'coco_subframes.json' correctly saved at '/general_dataset/sub_frames_500/test'.\n","\n"]}],"source":["# Creating subframes from the images stored in the testing dataset.\n","json_dic = subexport(\n","        img_dir = test_images_directory,\n","        img_anno_path = test_annotations_file,\n","        sfm_width = subframe_width,\n","        sfm_height = subframe_height,\n","        sfm_output_dir = test_subframes_directory,\n","        sfm_overlap = False,\n","        sfm_strict = True,\n","        print_rate = 50,\n","        sfm_object_only = False,\n","        sfm_anno_export = True\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #7 - Validating the sub-frames created for the training, validation and testing datasets**"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Results of the validation phase:\n","   - With 928 images in the training dataset...\n","         4029 subframes were created.\n","\n","   - With 111 images in the validation dataset...\n","         9781 subframes were created.\n","\n","   - With 258 images in the testing dataset...\n","         22266 subframes were created.\n"]}],"source":["validation_dict = {\n","    \"train_images_count\": 0,\n","    \"train_subframes_count\": 0,\n","    \"val_images_count\": 0,\n","    \"val_subframes_count\": 0,\n","    \"test_images_count\": 0,\n","    \"test_subframes_count\": 0\n","}\n","\n","for file in os.listdir(train_images_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"train_images_count\"] += 1\n","\n","for file in os.listdir(train_subframes_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"train_subframes_count\"] += 1\n","\n","for file in os.listdir(val_images_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"val_images_count\"] += 1\n","\n","for file in os.listdir(val_subframes_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"val_subframes_count\"] += 1\n","\n","for file in os.listdir(test_images_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"test_images_count\"] += 1\n","\n","for file in os.listdir(test_subframes_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"test_subframes_count\"] += 1\n","\n","print(\"Results of the validation phase:\\n\"\n","      \"   - With {} images in the training dataset...\\n\"\n","      \"         {} subframes were created.\\n\\n\"\n","      \"   - With {} images in the validation dataset...\\n\"\n","      \"         {} subframes were created.\\n\\n\"\n","      \"   - With {} images in the testing dataset...\\n\"\n","      \"         {} subframes were created.\"\n","      .format(validation_dict[\"train_images_count\"], validation_dict[\"train_subframes_count\"], validation_dict[\"val_images_count\"], \n","      validation_dict[\"val_subframes_count\"], validation_dict[\"test_images_count\"], validation_dict[\"test_subframes_count\"]))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOB4ljirr/lwScSJKJp9cMY","name":"export_subframes.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}
