{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **General information**"]},{"cell_type":"markdown","metadata":{},"source":["The purpose of this script is to set up the directories for the general dataset that will be used throughout the process of creating the detection model."]},{"cell_type":"markdown","metadata":{},"source":["### **Step #01 - Importing relevant Python libraries**"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from utils.Subframes import Subframes, subexport"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #02 - Creating directories to save the sub-frames**"]},{"cell_type":"markdown","metadata":{},"source":["A total of three new directories will be created for the training, validation and testing dataset. "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["!mkdir -p /general_dataset/sub_frames_500/train\n","!mkdir -p /general_dataset/sub_frames_500/val\n","!mkdir -p /general_dataset/sub_frames_500/test"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #03 - Creating the variables used to create the directories for the dataset**"]},{"cell_type":"markdown","metadata":{},"source":["The variables that need to be created are the following:\n","- Directories for the original unsliced training, validation and testing images ;\n","- Directories for the original unsliced training, validation and testing images' annotations ;\n","- File for the original unsliced training, validation and testing images' annotations ;\n","- The sub-frame's width and height."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["train_images_directory = \"/general_dataset/train\"\n","train_annotations_file = \"/general_dataset/groundtruth/json/big_size/train_big_size_A_B_E_K_WH_WB.json\"\n","train_subframes_directory = \"/general_dataset/sub_frames_500/train\"\n","\n","val_images_directory = \"/general_dataset/val\"\n","val_annotations_file = \"/general_dataset/groundtruth/json/big_size/val_big_size_A_B_E_K_WH_WB.json\"\n","val_subframes_directory = \"/general_dataset/sub_frames_500/val\"\n","\n","test_images_directory = \"/general_dataset/test\"\n","test_annotations_file = \"/general_dataset/groundtruth/json/big_size/test_big_size_A_B_E_K_WH_WB.json\"\n","test_subframes_directory = \"/general_dataset/sub_frames_500/test\"\n","\n","subframe_width = 500\n","subframe_height = 500"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #04 - Creating the sub-frames for the training dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating subframes from the images stored in the training dataset.\n","json_dic = subexport(\n","        img_dir = train_images_directory,\n","        img_anno_path = train_annotations_file,\n","        sfm_width = subframe_width,\n","        sfm_height = subframe_height,\n","        sfm_output_dir = train_subframes_directory,\n","        sfm_overlap = False,\n","        sfm_strict = True,\n","        print_rate = 50,\n","        sfm_object_only = True,\n","        sfm_anno_export = True\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #05 - Creating the sub-frames for the validation dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating subframes from the images stored in the validation dataset.\n","json_dic = subexport(\n","        img_dir = val_images_directory,\n","        img_anno_path = val_annotations_file,\n","        sfm_width = subframe_width,\n","        sfm_height = subframe_height,\n","        sfm_output_dir = val_subframes_directory,\n","        sfm_overlap = False,\n","        sfm_strict = True,\n","        print_rate = 50,\n","        sfm_object_only = False,\n","        sfm_anno_export = True\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #06 - Creating the sub-frames for the testing dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating subframes from the images stored in the testing dataset.\n","json_dic = subexport(\n","        img_dir = test_images_directory,\n","        img_anno_path = test_annotations_file,\n","        sfm_width = subframe_width,\n","        sfm_height = subframe_height,\n","        sfm_output_dir = test_subframes_directory,\n","        sfm_overlap = False,\n","        sfm_strict = True,\n","        print_rate = 50,\n","        sfm_object_only = False,\n","        sfm_anno_export = True\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["### **Step #7 - Validating the sub-frames created for the training, validation and testing datasets**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["validation_dict = {\n","    \"train_images_count\": 0,\n","    \"train_subframes_count\": 0,\n","    \"val_images_count\": 0,\n","    \"val_subframes_count\": 0,\n","    \"test_images_count\": 0,\n","    \"test_subframes_count\": 0\n","}\n","\n","for file in os.listdir(train_images_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"train_images_count\"] += 1\n","\n","for file in os.listdir(train_subframes_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"train_subframes_count\"] += 1\n","\n","for file in os.listdir(val_images_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"val_images_count\"] += 1\n","\n","for file in os.listdir(val_subframes_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"val_subframes_count\"] += 1\n","\n","for file in os.listdir(test_images_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"test_images_count\"] += 1\n","\n","for file in os.listdir(test_subframes_directory):\n","    if file.endswith(\".JPG\"):\n","        validation_dict[\"test_subframes_count\"] += 1\n","\n","print(\"Results of the validation phase:\\n\"\n","      \"   - With {} images in the training dataset...\\n\"\n","      \"         {} subframes were created.\\n\\n\"\n","      \"   - With {} images in the validation dataset...\\n\"\n","      \"         {} subframes were created.\\n\\n\"\n","      \"   - With {} images in the testing dataset...\\n\"\n","      \"         {} subframes were created.\"\n","      .format(validation_dict[\"train_images_count\"], validation_dict[\"train_subframes_count\"], validation_dict[\"val_images_count\"], \n","      validation_dict[\"val_subframes_count\"], validation_dict[\"test_images_count\"], validation_dict[\"test_subframes_count\"]))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOB4ljirr/lwScSJKJp9cMY","name":"export_subframes.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}
