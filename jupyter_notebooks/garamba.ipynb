{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"garamba.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMG0EPxPrrQKE8ifwUoasOk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jkXrdJ15dBLW"},"source":["# GPU\n","You must need a GPU of 16GB for inference with sub-frames of 2,000x2,000 pixels !"]},{"cell_type":"code","metadata":{"id":"CfDNeb5Wcx-1"},"source":["import torch\n","\n","# GPU\n","t = torch.cuda.get_device_properties(0).total_memory\n","t_GB = t/float((1024**3))\n","name = torch.cuda.get_device_name()\n","print('[GPU] Name : {:s} | Memory : {:.2f} GB'.format(name,t_GB))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5j1mt55dD26"},"source":["# Mount to your Drive\n","Note that annotations and images must be in your drive."]},{"cell_type":"code","metadata":{"id":"426ABl-XdHvk"},"source":["# Connection to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ikY3nBYdKDI"},"source":["# Installations\n","You first need to import the mmdetection folder into your drive.\n","At the end of the installations, you will need to restart runtime, just click on the suggested button. Then, go the next section and run the cells."]},{"cell_type":"code","metadata":{"id":"j59aGaUIdL5v"},"source":["import os\n","from os.path import exists, join, basename, splitext\n","import shutil\n","import sys\n","import torch\n","\n","# MMDetection directory (local)\n","mmdetection_dir = '/content/drive/My Drive/mmdetection'\n","print(\"MMdetection path : {}\".format(mmdetection_dir))\n","\n","# Installations of dependencies\n","!pip install parse\n","!pip install torch==1.4.0 torchvision==0.5.0\n","!pip install -q mmcv==0.6.0 terminaltables\n","\n","# Installation of MMDetection\n","!cd {mmdetection_dir} && python setup.py install\n","!pip install -r \"/content/drive/My Drive/mmdetection/requirements.txt\"\n","\n","# Path to system\n","sys.path.append(mmdetection_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I3-ZcIGkdRqd"},"source":["# Inference on Garamba dataset"]},{"cell_type":"code","metadata":{"id":"8mTpY7xjdVki"},"source":["# Develop MMDetection\n","mmdetection_dir = '/content/drive/My Drive/mmdetection'\n","%cd {mmdetection_dir}\n","!python setup.py develop"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tx1cBHVLwDTO"},"source":["## Useful functions"]},{"cell_type":"code","metadata":{"id":"aTzr5fWIwFMZ"},"source":["import os\n","from PIL import Image\n","from albumentations import Compose, BboxParams, Crop\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import math\n","import numpy as np\n","import torch\n","import torchvision\n","from torch.utils.data import Dataset\n","import json\n","import time\n","import datetime\n","from datetime import date\n","import csv\n","from os.path import exists, join, basename, splitext\n","from mmdet.apis import inference_detector, init_detector\n","import collections\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","from collections import Counter\n","import shutil\n","\n","class Subframes(object):\n","    ''' \n","    Class allowing the visualisation and the cropping of a labeled \n","    image (bbox) into sub-frames whose dimensions are specified \n","    by the user.\n","\n","    Attributes\n","    -----------\n","    img_name : str\n","        name of the image (with extension, e.g. \"My_image.JPG\").\n","    image : PIL\n","        PIL image.\n","    target : dict\n","        Must have 'boxes' and 'labels' keys at least.\n","        'boxes' must be a list in the 'coco' bounding box format :\n","        [[xmin, ymin, width, height], ...]\n","    width : int\n","        width of the sub-frames\n","    height : int\n","        height of the sub-frames\n","    strict : bool\n","        set to True get sub-frames of exact same size \n","        (e.g width x height) (default: False)\n","    \n","    Methods\n","    --------\n","    getlist(overlap=False)\n","        Produces a results list containing, for each row :\n","        the sub-frame (3D list, dtype=uint8), the bboxes (2D list),\n","        the labels (1D list) and the filename (str).\n","    visualise(results)\n","        Displays ordered sub-frames of the entire image.\n","    topoints(results)\n","        Converts the bounding boxes into points annotations.\n","    displayobjects(results, points_results, ann_type='point')\n","        Displays only sub-frames containing objects.\n","    save(results, output_path, object_only=True)\n","        Saves sub-frames to a specific path.\n","    '''\n","\n","    def __init__(self, img_name, image, target, width, height, strict=False):\n","        '''\n","        Parameters\n","        -----------\n","        img_name : str\n","            name of the image (with extension, e.g. \"My_image.JPG\")\n","        image : PIL\n","            PIL image\n","        target : dict\n","            Must have 'boxes' and 'labels' keys at least.\n","        width : int\n","            width of the sub-frames\n","        height : int\n","            height of the sub-frames\n","        strict : bool\n","            set to True get sub-frames of exact same size \n","            (e.g width x height) (default: False)\n","        '''\n","\n","        self.img_name = img_name\n","        self.image = image\n","        self.target = target\n","        self.width = width\n","        self.height = height\n","        self.strict = strict\n","\n","        self.img_width = image.size[0]\n","        self.img_height = image.size[1]\n","\n","        self.x_sub = 1 + int((self.img_width - (self.img_width % width)) / width)\n","        self.y_sub = 1 + int((self.img_height - (self.img_height % height)) / height)\n","\n","    def getlist(self, overlap=False):\n","        '''\n","        Produces a results list containing, for each row :\n","        the sub-frame (3D list, dtype=uint8), the bboxes (2D list),\n","        the labels (1D list) and the filename (str).\n","        Parameters\n","        -----------\n","        overlap : bool, optional\n","            Set to True to get an overlap of 50% between \n","            2 sub-frames (default: False)\n","        Returns\n","        --------\n","        list\n","        '''\n","        height = self.height\n","        width = self.width\n","        img_height = self.img_height\n","        img_width = self.img_width\n","\n","        results = []\n","\n","        # Image preprocessing      \n","        image_np = np.array(self.image)\n","        boxes = self.target['boxes']\n","        labels = self.target['labels']\n","        annotations = {'image':image_np,'bboxes':boxes,'labels':labels}\n","\n","        # Crop lists\n","        if overlap is True:\n","            overlap = 0.5\n","            y_sub = int(np.round(height*overlap))\n","            x_sub = int(np.round(width*overlap))\n","            rg_ymax = img_height-y_sub\n","            rg_xmax = img_width-x_sub\n","        else:\n","            y_sub = height\n","            x_sub = width\n","            rg_ymax = img_height\n","            rg_xmax = img_width\n","\n","        crops = []\n","\n","        for y in range(0, rg_ymax, y_sub):\n","            if  y+height <= img_height:\n","                for x in range(0, rg_xmax, x_sub):\n","                    if  x+width <= img_width:\n","                        xmin, ymin = x, y\n","                        xmax, ymax = x+width, y+height\n","                    elif x+img_width%width <= img_width:\n","                        xmin, ymin = img_width - width, y\n","                        xmax, ymax = x+img_width%width, y+height\n","\n","                    if self.strict is True:\n","                        crops.append([xmin, ymin, xmax, ymax])\n","                    else:\n","                        crops.append([x, y, xmax, ymax])\n","            \n","            elif  y+img_height%height <= img_height:\n","                for x in range(0, rg_xmax, x_sub):\n","                    if  x+width <= img_width:\n","                        xmin, ymin = x, img_height - height\n","                        xmax, ymax = x+width, y+img_height%height\n","                    elif x+img_width%width <= img_width:\n","                        xmin, ymin = img_width - width, img_height - height\n","                        xmax, ymax = x+img_width%width, y+img_height%height\n","\n","                    if self.strict is True:\n","                        crops.append([xmin, ymin, xmax, ymax])\n","                    else:\n","                        crops.append([x, y, xmax, ymax])\n","\n","        sub = 0\n","        for xmin, ymin, xmax, ymax in crops:\n","            transf = Compose([Crop(xmin, ymin, xmax, ymax, p=1.0)], \n","                                bbox_params=BboxParams(format='coco',\n","                                                        min_visibility=0.25, \n","                                                        label_fields=['labels']))\n","            augmented  = transf(**annotations)\n","            sub_name = self.img_name.rsplit('.')[0] + \"_S\" + str(sub) + \".JPG\"\n","            results.append([augmented['image'],augmented['bboxes'],augmented['labels'],sub_name])\n","            sub += 1\n","\n","        return results\n","\n","    def visualise(self, results):\n","        '''\n","        Displays ordered sub-frames of the entire image.\n","        Parameters\n","        -----------\n","        results : list\n","            The list obtained by the method getlist().\n","        Returns\n","        --------\n","        matplotlib plot\n","        '''\n","\n","        if len(results) > (self.x_sub*self.y_sub):\n","            x_sub = 2*self.x_sub - 2\n","            y_sub = 2*self.y_sub - 2\n","        else:\n","            x_sub = self.x_sub\n","            y_sub = self.y_sub\n","\n","        plt.figure(1)\n","        plt.suptitle(self.img_name)\n","        sub = 1\n","        for line in range(len(results)):\n","\n","            if self.img_width % self.width != 0:\n","                n_col = x_sub\n","                n_row = y_sub\n","            else:\n","                n_col = x_sub - 1\n","                n_row = y_sub - 1\n","\n","            plt.subplot(n_row, n_col, sub, xlim=(0,self.width), ylim=(self.height,0))\n","            plt.imshow(Image.fromarray(results[line][0]))\n","            plt.axis('off')\n","            plt.subplots_adjust(wspace=0.1,hspace=0.1)\n","\n","            text_x = np.shape(results[line][0])[1]\n","            text_y = np.shape(results[line][0])[0]\n","\n","            if self.width > self.height:\n","                f = self.height*(self.y_sub/y_sub)\n","            else:\n","                f = self.width*(self.x_sub/x_sub)\n","\n","            plt.text(0.5*text_x, 0.5*text_y, \n","                    \"S\"+str(line),\n","                    horizontalalignment='center',\n","                    verticalalignment='center',\n","                    fontsize=0.02*f,\n","                    color='w')\n","            sub += 1\n","\n","    def topoints(self, results):\n","        '''\n","        Converts the bounding boxes into points annotations.\n","        Parameters\n","        -----------\n","        results : list\n","            The list obtained by the method getlist().\n","        Returns\n","        --------\n","        list\n","            A 2D list with headers : \"id\", \"filename\", \"count\",\n","            \"locations\" where\n","            - \"id\" represents the unique id of the sub-frame within \n","              the image\n","            - \"filename\" is the name of the sub-frame \n","              (e.g. \"My_image_S1.JPG\")\n","            - \"count\" is the number of objects into the sub-frame\n","            - \"points\" is a list of tuple representing the \n","              locations of the objects (y,x)\n","    \n","        '''\n","\n","        points_results = [['id','filename','count','locations']]\n","        loc = []\n","        for line in range(len(results)):\n","            # Verify that bbox exists\n","            if results[line][1]:\n","                count = len(results[line][1])\n","                for bbox in range(len(results[line][1])):\n","                    boxe = results[line][1][bbox]\n","                    x = int(boxe[0]+(boxe[2])/2)\n","                    y = int(boxe[1]+(boxe[3])/2)\n","                    point = (y,x)\n","                    loc.append(point)\n","            \n","                sub_name = self.img_name.rsplit('.')[0] + \"_S\" + str(line) + \".JPG\"\n","                points_results.append([line, sub_name, count, loc])\n","                loc = []\n","\n","        return points_results\n","\n","    def displayobjects(self, results, points_results, ann_type='point'):\n","        '''\n","        Displays only sub-frames containing objects.\n","        Parameters\n","        -----------\n","        results : list\n","            The list obtained by the method getlist().\n","        points_results : list\n","            The list obtained by the method topoints(results).\n","        ann_type : str, optional\n","            A string used to specify the annotation type. Choose\n","            between :\n","            - 'point' to visualise points\n","            - 'bbox' to visualise bounding boxes\n","            - 'both' to visualise both\n","            (default is 'point')\n","        Returns\n","        --------\n","        matplotlib plot\n","        '''\n","\n","        sub_r = 0\n","        sub_c = 0\n","\n","        n_row = int(np.round(math.sqrt(len(points_results)-1)))\n","        n_col = n_row\n","\n","        if int(len(points_results)-1) > int(n_row*n_col):\n","            n_row += 1\n","\n","        fig, ax = plt.subplots(nrows=n_row, ncols=n_col, squeeze=False)\n","\n","        for r in range(n_row):\n","            for c in range(n_col):\n","                ax[r,c].axis('off')\n","                plt.subplots_adjust(wspace=0.1,hspace=0.1)\n","\n","        for o in range(1,len(points_results)):\n","\n","            id_object = points_results[o][0]\n","            patch_object = results[id_object][0]\n","\n","            text_x = np.shape(results[id_object][0])[1]\n","            text_y = np.shape(results[id_object][0])[0]\n","\n","            # Plot\n","            ax[sub_r,sub_c].imshow(Image.fromarray(patch_object))\n","            ax[sub_r,sub_c].text(0.5*text_x, 0.5*text_y, \n","                    \"S\"+str(id_object),\n","                    horizontalalignment='center',\n","                    verticalalignment='center',\n","                    fontsize=15,\n","                    color='w',\n","                    alpha=0.6)\n","\n","            if ann_type == 'point':\n","                points = points_results[o][3]\n","                for p in range(len(points)):\n","                    ax[sub_r,sub_c].scatter(points[p][1],points[p][0], color='r')\n","            \n","            elif ann_type == 'bbox':\n","                bboxes = results[id_object][1]\n","                for b in range(len(bboxes)):\n","                    rect = patches.Rectangle((bboxes[b][0],bboxes[b][1]),bboxes[b][2],bboxes[b][3], linewidth=1, edgecolor='r', facecolor='none')\n","                    ax[sub_r,sub_c].add_patch(rect)\n","                \n","            elif ann_type == 'both':\n","                points = points_results[o][3]\n","                bboxes = results[id_object][1]\n","                for b in range(len(bboxes)):\n","                    ax[sub_r,sub_c].scatter(points[b][1],points[b][0], color='b')\n","                    rect = patches.Rectangle((bboxes[b][0],bboxes[b][1]),bboxes[b][2],bboxes[b][3], linewidth=1, edgecolor='r', facecolor='none')\n","                    ax[sub_r,sub_c].add_patch(rect)\n","\n","            else:\n","                raise ValueError('Annotation of type \\'{}\\' unsupported. Choose between \\'point\\',\\'bbox\\' or \\'both\\'.'.format(ann_type))\n","                \n","            if sub_c < n_col-1:\n","                sub_r = sub_r\n","                sub_c += 1\n","            else:\n","                sub_c = 0\n","                sub_r += 1\n","            \n","    def save(self, results, output_path, object_only=True):\n","        '''\n","        Saves sub-frames (.JPG) to a specific path.\n","        Parameters\n","        -----------\n","        results : list\n","            The list obtained by the method getlist().\n","        output_path : str\n","            The path to the folder chosen to save sub-frames.\n","        object_only : bool, optional\n","            A flag used to choose between :\n","            - saving all the sub-frames of the entire image\n","              (set to False)\n","            - saving only sub-frames with objects\n","              (set to True, default)\n","        Returns\n","        --------\n","        None\n","        '''\n","\n","        for line in range(len(results)):\n","            if object_only is True:\n","                if results[line][1]:\n","                    subframe = Image.fromarray(results[line][0])\n","                    sub_name =  results[line][3]\n","                    subframe.save(os.path.join(output_path, sub_name))\n","                    \n","            elif object_only is not True:\n","                subframe = Image.fromarray(results[line][0])\n","                sub_name =  results[line][3]\n","                subframe.save(os.path.join(output_path, sub_name))\n","\n","def softnms(preds, Nt, tresh, method='linear', sigma=0.5):\n","    '''\n","    Function for applying the Non-Maximum Suppression \n","    (NMS) filter and Soft-NMS.\n","\n","    Parameters\n","    ----------\n","    preds : dict\n","        Contains, at least, 3 keys:\n","          - 'boxes' : list, containing a list of \n","            predicted bounding boxes,\n","          - 'labels' : int, containing a list of labels\n","            associated to the bboxes,\n","          - 'scores' : float, containing confidence \n","            scores associated to predictions.\n","    \n","    Nt : float\n","        IoU treshold to apply.\n","\n","    tresh : float\n","        Scores treshold.\n","    \n","    method : str, optional\n","        Choose between:\n","          - 'nms' for classical non-soft NMS\n","          - 'linear' for linear Soft-NMS\n","          - 'gaussian' for gaussian Soft-NMS\n","\n","        In this third case, it is possible to\n","        specify the variance, by changing 'sigma'.\n","\n","        Default: 'linear'\n","    \n","    sigma : float, optional\n","        Variance of gaussian's curve.\n","\n","        Default: 0.5\n","\n","\n","    Returns\n","    -------\n","    dict\n","        Contains the 3 initial keys including filtered\n","        values.\n","\n","    Notes\n","    -----\n","    Based on:\n","      - https://github.com/DocF/Soft-NMS/blob/master/soft_nms.py\n","      - https://github.com/bharatsingh430/soft-nms/blob/master/lib/nms/cpu_nms.pyx\n","\n","    '''\n","\n","    boxes = np.array(preds['boxes'])\n","    labels = np.array(preds['labels'])\n","    scores = np.array(preds['scores'])\n","\n","    boxes_f = boxes.copy()\n","    labels_f = labels.copy()\n","    scores_f = scores.copy()\n","\n","    if len(boxes)==0:\n","        return []\n","\n","    if boxes.dtype.kind == \"i\":\n","\t\t    boxes = boxes.astype(\"float\")\n","\n","    N = boxes.shape[0]\n","    ind = np.array([np.arange(N)])\n","    boxes = np.concatenate((boxes, ind.T), axis=1)\n","\n","    x1 = boxes[:,0]\n","    y1 = boxes[:,1]\n","    x2 = boxes[:,2]\n","    y2 = boxes[:,3]\n","\n","    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n","\n","    for i in range(N):\n","\n","        # temporary variables\n","        t_boxes = boxes[i, :].copy()\n","        t_score = scores[i].copy()\n","        t_area = areas[i].copy()\n","        pos = i + 1\n","\n","        if i != N-1:\n","            max_score = np.max(scores[pos:], axis=0)\n","            max_pos = np.argmax(scores[pos:], axis=0)\n","\n","        else:\n","            max_score = scores[-1]\n","            max_pos = 0\n","\n","        if t_score < max_score:\n","            boxes[i, :] = boxes[max_pos + i + 1, :]\n","            boxes[max_pos + i + 1, :] = t_boxes\n","            t_boxes = boxes[i,:]\n","\n","            scores[i] = scores[max_pos + i + 1]\n","            scores[max_pos + i + 1] = t_score\n","            t_score = scores[i]\n","\n","            areas[i] = areas[max_pos + i + 1]\n","            areas[max_pos + i + 1] = t_area\n","            t_area = areas[i]\n","\n","        # compute IoU\n","        xx1 = np.maximum(boxes[i, 0], boxes[pos:, 0])\n","        yy1 = np.maximum(boxes[i, 1], boxes[pos:, 1])\n","        xx2 = np.minimum(boxes[i, 2], boxes[pos:, 2])\n","        yy2 = np.minimum(boxes[i, 3], boxes[pos:, 3])\n","\n","\n","        w = np.maximum(0.0, xx2 - xx1 + 1)\n","        h = np.maximum(0.0, yy2 - yy1 + 1)\n","\n","        # IoU\n","        iou = (w * h) / (areas[i] + areas[pos:] - (w * h))\n","\n","        # Weigthing\n","        # ---\n","        # 1 - Linear\n","        if method == 'linear':\n","            weight = np.ones(iou.shape)\n","            weight[iou > Nt] = weight[iou > Nt] - iou[iou > Nt]\n","        # 2 - Gaussian\n","        elif method == 'gaussian':\n","            weight = np.exp(-(iou*iou)/sigma)\n","        # 3 - Original\n","        elif method == 'nms':\n","            weight = np.ones(iou.shape)\n","            weight[iou > Nt] = 0\n","\n","        scores[pos:] = weight * scores[pos:]\n","  \n","    idx = boxes[:,4][scores > tresh]\n","    pick = idx.astype(int)\n","\n","    return {'boxes':boxes_f[pick],'labels':labels_f[pick],'scores':scores_f[pick]}\n","\n","def overlap_merging(img_path, coco_path, width, height, output_path, \n","                    mmdet_model, nms_method='nms', IoU=0.3, sc_tresh=0.5):\n","    '''\n","    Function to perform inference and stitching of the \n","    resulting predictions on a big-sized image cut into \n","    sub-frames with 50% overlap, in order to obtain the \n","    original image and its predictions.\n","\n","    To be used with the Subframes class.\n","\n","    Parameters\n","    ----------\n","    img_path : str\n","        Path to the image.\n","\n","    coco_path : str\n","        Path to the COCO-annotation type (JSON).\n","    \n","    width : int\n","        Width of the sub-frames.\n","\n","    height : int\n","        Height of the sub-frames.\n","    \n","    output_path : str\n","        Sub-frames saving path.\n","    \n","    mmdet_model : object\n","        Model built from mmdet.apis.init_detector\n","\n","    nms_method : str, optional\n","        NMS method to apply to bounding boxes.\n","        Choose between:\n","            - 'nms' : for classic NMS\n","            - 'linear' : for linear soft-NMS\n","            - 'gaussian' : for gaussian soft-NMS (sigma=0.5)\n","        Default : 'nms'\n","\n","    IoU : float, optional\n","        (Soft-)NMS treshold.\n","        Default : 0.3\n","    \n","    sc_tresh : float, optional\n","        Scores treshold to applay on predictions.\n","        Default : 0.5\n","\n","    Returns\n","    -------\n","    dict\n","        Resulting predictions containing 3 keys:\n","          - 'boxes' (2D array)\n","          - 'labels' (1D array)\n","          - 'scores' (1D array)\n","    '''\n","\n","    t_i = time.time()\n","\n","    with open(coco_path,'r') as json_file:\n","        coco_dic = json.load(json_file)\n","\n","    cls_names = []\n","    for cls in coco_dic['categories']:\n","        cls_names.append(cls['name'])\n","\n","    # PIL image\n","    pil_img = Image.open(img_path)\n","\n","    # Infos\n","    name = basename(img_path)\n","\n","    w_sub = int(pil_img.width/width)\n","    h_sub = int(pil_img.height/height)\n","\n","    if pil_img.width % width != 0:\n","        w_sub += 1\n","    if pil_img.height % height != 0:\n","        h_sub += 1\n","\n","\n","    # Export folder\n","    save_path = os.path.join(output_path,name)\n","    if os.path.exists(save_path) is not True:\n","        os.mkdir(save_path)\n","\n","    # Get annos\n","    for image in coco_dic['images']:\n","        if image['file_name'] == name:\n","            img_id = image['id']\n","\n","    boxes = []\n","    labels = []\n","    for ann in coco_dic['annotations']:\n","        if ann['image_id'] == img_id:\n","            boxes.append(ann['bbox'])\n","            labels.append(ann['category_id'])\n","\n","    gt = {'boxes':boxes, 'labels':labels}\n","\n","    # Subframes class instantiation\n","    sub_img = Subframes(name, pil_img, gt, width, height)\n","\n","    # overlap\n","    results = sub_img.getlist(overlap=True)\n","\n","    sub_img.save(results, save_path, object_only=False)\n","\n","    os.chdir(save_path)\n","    files = os.listdir(save_path)\n","    files.sort(key=os.path.getctime)\n","\n","    files_2D = np.reshape(np.array(files), (2*h_sub-1,2*w_sub-1))\n","\n","    # Initializations\n","    w_offset = 0\n","    h_offset = 0\n","    global_boxes = []\n","    global_labels = []\n","    global_scores = []\n","\n","    for y in range(files_2D.shape[0]):\n","        for x in range(files_2D.shape[1]):\n","\n","            # Image\n","            image = files_2D[y,x]\n","\n","            # Predictions\n","            predictions = inference_detector(mmdet_model, image)\n","\n","            # adapt\n","            boxes = []\n","            labels = []\n","            scores = []\n","            for n_class in range(len(cls_names)):\n","                for n_box in range(len(predictions[n_class])):\n","                    box = list(predictions[n_class][n_box][:4])\n","                    score = predictions[n_class][n_box][4]\n","                    boxes.append(box)\n","                    labels.append(n_class+1)\n","                    scores.append(score)\n","\n","            predictions = {'boxes': boxes, 'labels': labels, 'scores': scores}\n","\n","            # Put into a global frame\n","            i = 0\n","            for box in predictions['boxes']:\n","\n","                new_box = [box[0] + w_offset,\n","                          box[1] + h_offset,\n","                          box[2] + w_offset,\n","                          box[3] + h_offset]            \n","                \n","                global_boxes.append(new_box)\n","                global_labels.append(predictions['labels'][i])\n","                global_scores.append(predictions['scores'][i])\n","\n","                i += 1\n","\n","            w_offset += 0.5*width\n","\n","        w_offset = 0\n","        h_offset += 0.5*height\n","\n","    global_preds = {\n","        'boxes':global_boxes, \n","        'labels':global_labels,\n","        'scores':global_scores\n","        }\n","\n","    # Soft-NMS \n","    global_preds = softnms(global_preds, IoU, sc_tresh, method=nms_method)\n","\n","    t_f = time.time()\n","\n","    shutil.rmtree(save_path)\n","\n","    return global_preds\n","\n","class ModelPerformances(object):\n","    '''\n","    Class to obtain the performances of an object detection model \n","    based on 2 csv files: the groundtruth and the detections.\n","\n","    The groundtruth file must contain a header of :\n","    | 'Image' | 'x1' | 'y1' | 'x2' | 'y2' | 'Label' |\n","\n","    The detections file must contain a header of :\n","    | 'Image' | 'x1' | 'y1' | 'x2' | 'y2' | 'Label' | 'Score' |\n","\n","    Note that the labels must obviously correspond between the \n","    groundtruth and the detections.\n","\n","    ...\n","\n","    Attributes\n","    ----------\n","    gt_path : str\n","        Path to the groundtruth CSV file\n","    det_path : str\n","        Path to the detection CSV file\n","    gt : DataFrame\n","        DataFrame from the groundtruth CSV file\n","    det : DataFrame\n","        DataFrame from the detection CSV file\n","    IoU : float\n","        IoU threshold\n","    match : DataFrame\n","        DataFrame created by 'compare' property. Contains comparison\n","        between detections and groundtruth\n","    seen_objects : dict\n","        Dictionnary with image name as keys and list as value.\n","        In list, 0 means object not seen (no match with a detection),\n","        and 1 seen\n","    \n","    Properties\n","    ----------\n","    compare\n","        Compare detections and ground truth\n","    pr_table\n","        Get table with, among others things, precision and recall\n","        values for each confidence score\n","    confusion_matrix\n","        Compute confusion matrix\n","    results_table\n","        Get table with performances of each category (precision, recall,\n","        F1-scores, confusion between categories, FP/TP ratio, Average\n","        Precision)\n","    mAP\n","        Compute the mean Average Precision (mAP)\n","    binary\n","        Get table with performances of the model as it was a binary case\n","        object vs background (precision, recall, F1-scores, FP/TP ratio)\n","    max_f1\n","        Find maximum F1-scores and corresponding precision, recall\n","        and score\n","\n","    '''\n","\n","    def __init__(self, gt, det, IoU):\n","        '''\n","        Parameters\n","        ----------\n","        gt : str\n","            Path to the groundtruth CSV file\n","        det : str\n","            Path to the detection CSV file\n","        IoU : float\n","            IoU threshold\n","        '''\n","\n","        # Paths attributes\n","        self.gt_path = gt\n","        self.det_path = det\n","\n","        # Open files\n","        self.gt = pd.read_csv(gt)\n","        self.det = pd.read_csv(det)\n","\n","        self.IoU = IoU\n","\n","        self.match = self.compare\n","\n","    # Private methods\n","    # ---\n","    def __compute_IoU(self, box_A, box_B):\n","        '''\n","        Method to compute Intersect-over-Union (IoU)\n","        between two lists of boxes.\n","\n","        Parameters\n","        ----------\n","        box_A : list\n","            (dim=4) 2 points-style (upper-left (x1,y1) and \n","            bottom-right (x2,y2))\n","\n","        box_B : list\n","            (dim=4) 2 points-style (upper-left (x1,y1) and \n","            bottom-right (x2,y2))\n","        \n","        Returns\n","        -------\n","        IoU : float\n","        '''\n","\n","        # DÃ©termination des coord. (x,y) de l'intersection\t\n","        xA = max(box_A[0],box_B[0])\t\n","        yA = max(box_A[1],box_B[1])\t\n","        xB = min(box_A[2],box_B[2])\t\n","        yB = min(box_A[3],box_B[3])\t\n","\n","        # Aire de cette intersection\t\n","        area = max(0, xB - xA +1) * max(0, yB - yA +1)\t\n","\n","        # Aires de la box A et de la box B\t\n","        area_A = (box_A[2] - box_A[0] + 1) * (box_A[3] - box_A[1] + 1)\t\n","        area_B = (box_B[2] - box_B[0] + 1) * (box_B[3] - box_B[1] + 1)\t\n","\n","        # Calcul de l'IoU\t\n","        IoU = area / float(area_A + area_B - area)\t\n","\n","        return IoU\n","\n","    def __AP(self, rec, prec):\n","        '''\n","        Method to compute the VOC Average Precision.\n","\n","        Code from: https://github.com/Cartucho/mAP\n","        (adapted from official matlab code VOC2012)\n","\n","        Parameters\n","        ----------\n","        rec : list\n","            Recall increasing values.\n","        prec : list\n","            Precision decreasing values.\n","\n","        Returns\n","        -------\n","        Average Precision : float\n","        \n","        '''\n","        rec.insert(0, 0.0)\n","        rec.append(1.0)\n","        mrec = rec[:]\n","        prec.insert(0, 0.0) \n","        prec.append(0.0) \n","        mpre = prec[:]\n","\n","        for i in range(len(mpre)-2, -1, -1):\n","            mpre[i] = max(mpre[i], mpre[i+1])\n","\n","        i_list = []\n","        for i in range(1, len(mrec)):\n","            if mrec[i] != mrec[i-1]:\n","                i_list.append(i) \n","\n","        ap = 0.0\n","        for i in i_list:\n","            ap += ((mrec[i]-mrec[i-1])*mpre[i])\n","\n","        return ap\n"," \n","    # Properties\n","    # ---\n","    @property\n","    def compare(self):\n","        '''\n","        Compare detections and ground truth.\n","\n","        Returns\n","        -------\n","        pd.DataFrame\n","            With additionals columns : \n","            - 'Assignment' which contains 'TP' or 'FP';\n","            - 'IoU';\n","            - 'GT' : with groundtruth's labels;\n","        '''\n","\n","        ground = self.gt.values.tolist()\n","        preds = self.det.values.tolist()\n","        IoU_t = self.IoU\n","\n","        # Initialize columns\n","        idx = 0\n","        for pred in preds:\n","            pred.append(0) # GT (7)\n","            pred.append('') # Assignment (8)\n","            pred.append(0.0) # IoU (9)\n","            pred.append(idx) # idx (10)\n","            idx += 1\n","\n","        # Get categories\n","        cat_gt = [int(row[5]) for row in ground]\n","        cat_p = [int(row[5]) for row in preds\n","                          if math.isnan(row[5]) is not True]\n","        cat = list(set(cat_gt + cat_p))\n","        \n","        # Create dictionary with amount of gts for each image\n","        seen_det = Counter([gt[0] for gt in ground])\n","        for key, val in seen_det.items():\n","            seen_det[key] = np.zeros(val)\n","\n","        # Loop through categories\n","        for c in cat:\n","\n","            # Get predictions\n","            preds_c = [p for p in preds if p[5]==c]\n","            # Sort by decreasing confidence score\n","            preds_c.sort(key=lambda x:x[6], reverse=True)\n","\n","            # Loop through predictions\n","            for p in preds_c:\n","\n","                # Get index of initial detections\n","                index = p[10]\n","\n","                # Find corresponding ground truth\n","                gt = [gt for gt in ground if p[0] in gt[0]]\n","\n","                # Initialize IoU and gt max\n","                iou_max = 0.0\n","\n","                # Loop through ground truth\n","                for j , g in zip(range(len(gt)),gt):\n","\n","                    # Compute IoU\n","                    gt_box , p_box = g[1:5] , p[1:5]\n","                    iou = self.__compute_IoU(gt_box,p_box)\n","\n","                    if iou > iou_max:\n","                        iou_max = iou\n","                        j_max = j\n","                        gt_max = g[5]\n","\n","                # Prediction assignment\n","                if iou_max >= IoU_t:\n","\n","                    if seen_det[p[0]][j_max] == 0:\n","\n","                        if gt_max==c:\n","                            # Assignment\n","                            preds[index][8] = 'TP'\n","                            # GT label\n","                            preds[index][7] = gt_max\n","\n","                        else:\n","                            # Assignment\n","                            preds[index][8] = 'FP'\n","                            # GT label\n","                            preds[index][7] = gt_max\n","\n","                        # Set 'Seen' flag to 1\n","                        seen_det[p[0]][j_max] = 1\n","\n","                    else:\n","                        preds[index][8] = 'FP'\n","\n","                else:\n","                    preds[index][8] = 'FP'\n","                \n","                # IoU\n","                preds[index][9] = iou_max\n","\n","        # Create a dataframe with the list of lists\n","        header = ['Image','x1','y1','x2','y2','Label','Score','GT','Assignment','IoU','id']\n","        match = pd.DataFrame(data=preds, columns=header)\n","\n","        # Attribute \"seen_objects\" \n","        self.seen_objects = seen_det\n","\n","        return match[['Image','x1','y1','x2','y2','Label','Score','GT','IoU','Assignment']]\n","\n","    @property\n","    def pr_table(self):\n","        '''\n","        To get table with, among others things, precision and recall\n","        values for each confidence score.\n","\n","        Returns\n","        -------\n","        pandas.DataFrame or dict\n","            Dataframe if only one category, otherwise dict with categories\n","            as keys and Dataframe as values\n","        '''\n","\n","        # Get matching between gt and detections\n","        # To list to save time\n","        match_df = self.match.values.tolist()\n","\n","        # List of categories\n","        categories = list(set(self.gt['Label']))\n","\n","        # Loop through categories\n","        all_cat = {}\n","        for cat in categories:\n","\n","            # Initialize a list\n","            res_df = []\n","\n","            # Get matches\n","            cat_df = [m for m in match_df if m[5]==cat]\n","            # Sort by decreasing confidence score\n","            cat_df.sort(key=lambda x:x[6], reverse=True)\n","\n","            # Groundtruth\n","            n_gt = len(self.gt[self.gt['Label']==cat])\n","\n","            # Initialize variable\n","            cum_tp = 0\n","            cum_fp = 0\n","\n","            # Fill in with matching results\n","            for row in cat_df:\n","\n","                # Compute cumulative TP and FP\n","                if row[9]=='TP':\n","                    tp , fp = 1 , 0\n","                    cum_tp += 1\n","                else:\n","                    tp , fp = 0 , 1\n","                    cum_fp += 1\n","\n","                # Add to list\n","                res_df.append(\n","                    [\n","                        row[5],\n","                        row[6],\n","                        tp,\n","                        fp,\n","                        cum_tp,\n","                        cum_fp,\n","                        cum_tp/(cum_tp+cum_fp),\n","                        cum_tp/n_gt\n","                    ]\n","                )\n","            \n","            # Transform list to DataFrame\n","            header = ['Detection','Score','TP','FP','Cum_TP','Cum_FP','Precision','Recall']\n","            res_df = pd.DataFrame(data=res_df, columns=header)\n","\n","            all_cat.update({cat : res_df})\n","\n","        if len(all_cat)==1:\n","            out_df = res_df\n","        else:\n","            out_df = all_cat\n","\n","        return out_df\n","\n","    @property\n","    def confusion_matrix(self):\n","        '''\n","        Compute confusion matrix.\n","\n","        Returns\n","        -------\n","        2D list\n","        '''\n","\n","        # Get data\n","        match_df = self.match\n","        all_gt = list(match_df['GT'])\n","        all_det = list(match_df['Label'])\n","\n","        # Use Sklearn's confusion matrix\n","        categories = list(set(list(set(all_gt)) + list(set(all_det))))\n","        categories = [int(c) for c in categories]\n","        matrix = confusion_matrix(all_gt, all_det, labels=categories)\n","        matrix = pd.DataFrame(data=matrix, columns=categories, index=categories)\n","\n","        # Add false negatives\n","        for cat in categories[1:]:\n","            matrix.at[cat,0] = len(self.gt[self.gt['Label']==cat]) - sum(matrix.loc[cat])\n","\n","        return matrix\n","    \n","    @property\n","    def results_table(self):\n","        '''\n","        Get table with performances of each category (precision, recall,\n","        F1-scores, confusion between categories, FP/TP ratio, Average\n","        Precision)\n","\n","        Returns\n","        -------\n","        pandas.DataFrame\n","        '''\n","\n","        # Call confusion_matrix method\n","        cm = self.confusion_matrix.values.tolist()\n","\n","        # Initialization\n","        mean_f1 = 0\n","        df = []\n","\n","        # Compute precision, recall, F1-score, confusion\n","        for row , cat in zip(cm[1:], range(1,len(cm))):\n","            tp = cm[cat][cat]\n","            fn = sum([c for c in cm[cat]]) - tp\n","            fp = sum([c[cat] for c in cm]) - tp\n","            precision = tp/(tp+fp)\n","            recall = tp/(tp+fn)\n","            confusion = 1 - (row[cat]/(sum(row)-row[0]))\n","\n","            if precision > 0 and recall > 0:\n","              f1_score = 2*precision*recall/(precision+recall)\n","              mean_f1 += f1_score\n","            else:\n","              f1_score = 0\n","              mean_f1 += f1_score\n","            \n","            # Append to DataFrame\n","            if tp == 0:\n","              fp_tp = 'inf'\n","            else:\n","              fp_tp = fp/tp\n","\n","            df.append(\n","                [\n","                  cat,\n","                  precision,\n","                  recall,\n","                  f1_score,\n","                  fp_tp,\n","                  confusion,\n","                  0.0\n","                ]              \n","            )\n","\n","        mean_f1 = mean_f1/len(cm)\n","\n","        # Get data for AP\n","        tables  = self.pr_table\n","\n","        # Loop through data\n","        for i,key in zip(range(len(tables)),tables):\n","\n","            # Precision and recall lists\n","            precision = list(tables[key]['Precision'])\n","            recall = list(tables[key]['Recall'])\n","\n","            # Compute AP\n","            ap = self.__AP(recall,precision)\n","\n","            df[i][6] = ap\n","\n","        # Transform list to DataFrame\n","        header = ['Category','Precision','Recall','F1-score','FP/TP','Confusion','AP']\n","        df = pd.DataFrame(data=df, columns=header)\n","\n","        return df\n","    \n","    @property\n","    def mAP(self):\n","        '''\n","        Compute the mean Average Precision (mAP).\n","        \n","        Returns\n","        -------\n","        float\n","        '''\n","\n","        # Get data\n","        tables = self.pr_table\n","\n","        # Loup through categories\n","        ap_list = []\n","        for key in tables:\n","\n","            # Precision and recall lists\n","            precision = list(tables[key]['Precision'])\n","            recall = list(tables[key]['Recall'])\n","\n","            # Compute AP\n","            ap = self.__AP(recall,precision)\n","            ap_list.append(ap)\n","        \n","        # Compute mean of APs\n","        m_ap = np.mean(ap_list)\n","\n","        return m_ap\n","    \n","    @property\n","    def binary(self):\n","        '''\n","        Get table with performances of the model as it was a binary case\n","        object vs background (precision, recall, F1-scores, FP/TP ratio)\n","\n","        Returns\n","        -------\n","        pandas.DataFrame\n","        '''\n","\n","        # Call confusion matrix method\n","        cm = self.confusion_matrix.values.tolist()\n","\n","        # Compute TP, FP, FN as a binary case\n","        tp = sum([sum(c[1:]) for c in cm[1:]])\n","        gt = sum([sum(c) for c in cm[1:]])\n","        fp = sum(cm[0])\n","\n","        # Compute Precision, Recall\n","        precision = tp/(tp+fp)\n","        recall = tp/gt\n","\n","        # Store into a DataFrame\n","        df = pd.DataFrame(\n","            data = {\n","                'Precision': [precision],\n","                'Recall': [recall],\n","                'F1-score': [2*precision*recall/(precision+recall)],\n","                'FP/TP': [fp/tp]\n","            }\n","        )\n","        \n","        return df\n","   \n","    @property\n","    def max_f1(self):\n","        '''\n","        Find maximum F1-scores and corresponding precision, recall\n","        and score.\n","\n","        Returns\n","        -------\n","        pandas.DataFrame\n","        '''\n","\n","        # Get data\n","        tables = self.pr_table\n","\n","        # Initialize a list\n","        df = []\n","\n","        # Loop through tables\n","        for cat , tab in tables.items():\n","            # Get precision and recall\n","            precision = list(tab['Precision'])\n","            recall = list(tab['Recall'])\n","\n","            # Compute F1-scores for each row\n","            f1_scores = []\n","            for pr, re in zip(precision, recall):\n","                # Avoid divid by 0\n","                if (pr + re) != 0:\n","                    f1_score = 2 * pr * re / (pr + re)\n","                else:\n","                    f1_score = 0\n","                \n","                f1_scores.append(f1_score)\n","            \n","            # Find the maximum\n","            f1_score_max = max(f1_scores)\n","            idx = f1_scores.index(f1_score_max)\n","\n","            # Append to list\n","            df.append([\n","                  cat,\n","                  f1_score_max,\n","                  tab.loc[idx,'Score'], \n","                  tab.loc[idx,'Precision'], \n","                  tab.loc[idx,'Recall'], \n","            ])\n","        \n","        # Transform list to DataFrame\n","        header = ['Category','F1-score','Score','Precision','Recall']\n","        df = pd.DataFrame(data = df, columns = header)\n","\n","        return df\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8WnLNEHtwZId"},"source":["## Detections"]},{"cell_type":"markdown","metadata":{"id":"_Trgzt-Fp01X"},"source":["### Fill with your paths\n","Warning, 'checkpoint' key now refers to **best Libra-RCNN model** determined during **test**, according to the mF1 and mAP as explained in the paper (so seed **1357**).\n","\n","Note also that the config file must refer to the one with the hard negative class !\n","\n","**You must upload all the ground truth files with numeric id for species, into /content !**"]},{"cell_type":"code","metadata":{"id":"vqLVk9GIp142"},"source":["# Flight images\n","flight_name = 'ENTER THE FLIGHT NAME'\n","images_folder = '< path to one Garamba UAV flight folder >'\n","\n","# Flight annotations\n","original_size_annos = '< path to your original size FLIGHT images annotations (.json) >'\n","\n","# Best model\n","model = {\n","    'libra_rcnn' : {\n","        'config_hnc' : '< path to the config file with hard negative class >',\n","        'checkpoint' : '< path to the BEST checkpoint FILE - seed 1357 - epoch 40 >',\n","        'out' : '< path to your outputs folder >'\n","    }\n","}\n","\n","# Best model is Libra-RCNN\n","model_name = 'libra_rcnn'\n","\n","# Best seed\n","seed = 1357"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dpl2__T9rEN9"},"source":["### Get detections for the specified UAV flight"]},{"cell_type":"code","metadata":{"id":"FeqXgw7urCrs"},"source":["import pandas as pd\n","from mmdet.apis import init_detector\n","import time\n","import datetime\n","from datetime import date\n","import numpy as np\n","import os\n","\n","# Initialize the model\n","model = init_detector(models[model_name]['config_hnc'], models[model_name]['checkpoint'])\n","\n","# Initialize DataFrame\n","df = pd.DataFrame(columns=['Image','x1','y1','x2','y2','Label','Score'])\n","\n","# Get images\n","images = os.listdir(images_folder)\n","if os.path.exists('/content/images_sub') is False:\n","    os.mkdir('/content/images_sub')\n","\n","# Start inference on images\n","t_start = time.time()\n","for i,image in zip(range(len(images)),images):\n","    t_i = time.time()\n","\n","    # Get predictions\n","    results = overlap_merging(\n","        img_path=os.path.join(images_folder,image),\n","        coco_path=original_size_annos,\n","        width=2000,\n","        height=2000,\n","        output_path='/content/images_sub',\n","        mmdet_model=model,\n","        IoU=0.5,\n","        sc_tresh=0.0\n","    )\n","\n","    t_f = time.time()\n","\n","    # Infos\n","    elapsed = str(datetime.timedelta(seconds=int(np.round(t_f-t_i))))\n","    print('Image [{}/{}] | Name : {} | Elapsed time : {}'\n","          .format(str(i+1), len(images), image, elapsed))\n","\n","    if bool(results):\n","        for box , label , score in zip(results['boxes'],results['labels'],results['scores']):\n","            df = df.append(\n","                {'Image':image,\n","                'x1':box[0],\n","                'y1':box[1],\n","                'x2':box[2],\n","                'y2':box[3],\n","                'Label':label,\n","                'Score':score},\n","                ignore_index=True\n","            )\n","    # If no predictions, add a blank row\n","    else:\n","        df = df.append(\n","            {'Image':image,\n","            'x1':None,\n","            'y1':None,\n","            'x2':None,\n","            'y2':None,\n","            'Label':None,\n","            'Score':None}, \n","            ignore_index = True\n","        )\n","\n","# Export to CSV\n","outpath = os.path.join(models[model_name]['out'],f'{flight_name}_{model_name}_{seed}_detections.csv')\n","df.to_csv(outpath, index=False)\n","\n","t_end = time.time()\n","\n","# Print final infos\n","elapsed_total = str(datetime.timedelta(seconds=int(np.round(t_end-t_start))))\n","print('Total elapsed time : {}'.format(elapsed_total))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xrxHXEK-t0l4"},"source":["# Analyse results\n","**Before running the next cells, you must have all the flights detections files !**"]},{"cell_type":"code","metadata":{"id":"GlPHcawNUEYx"},"source":["# Ground-truth folder that contains all numeric gt files\n","gt_folder = '< path >'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kbBBW_YxwqrR"},"source":["## 1) Get rid of hard negative class\n","Flights names must correspond to the names given above (section \"Detections\") !\n"]},{"cell_type":"code","metadata":{"id":"PIslt8qzwpQv"},"source":["# Get detections without negative class\n","flights_names = ['E1V1','E1V2','E1V3','E2V1','E2V2','E2V3a','E2V3b']\n","species_idx = [1,2,3,4,5,6]\n","\n","for flight in flights_names :\n","\n","    det_path = os.path.join(models[model_name]['out'],f'{flight}_{model_name}_{seed}_detections.csv')\n","    det_df = pd.read_csv(det_path)\n","\n","    det_df = det_df[det_df['Label']!=7].dropna()\n","\n","    # Save in local (/content)\n","    det_df.to_csv(f'/content/{flight}_{model_name}_{seed}_detections.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3FghPR9A0V3N"},"source":["## 2) Compute, print and save performances"]},{"cell_type":"code","metadata":{"id":"ekSLaQ63t-wV"},"source":["for flight in flights_names :\n","\n","    # Get performances\n","    perfs = ModelPerformances(\n","        gt = os.path.join(gt_folder, f'{flight}_groundtruth_numeric.csv'),\n","        det = f'/content/{flight}_{model_name}_{seed}_detections.csv',\n","        IoU = 0.3\n","        )\n","\n","    # Print results\n","    # ---\n","    print('---')\n","    print('FLIGHT : {}'.format(flight))\n","\n","    # Images\n","    gt = perfs.gt[perfs.gt['Label'].isin(species_idx)]\n","    gt_imgs = list(set(gt['Image']))\n","    det_imgs = list(set(perfs.det['Image']))\n","    missed = list(set(gt_imgs)-set(det_imgs))\n","    print('[IMAGES] Detected : {} | With animals : {} | Missed : {}'.format(len(det_imgs),len(gt_imgs),len(missed)))\n","\n","    # Animals\n","    identified = perfs.compare[perfs.compare['GT'].isin([0]+species_idx)]\n","    identified = identified[identified['Assignment']=='TP']\n","    print('[ANIMALS] Total : {} | Identified : {}'.format(len(gt),len(identified)))\n","\n","    # False positives\n","    fp = perfs.compare[perfs.compare['Assignment']=='FP']\n","    # Real fp are fp with iou = 0\n","    real_fp = perfs.compare[(perfs.compare['Assignment']=='FP')&(perfs.compare['IoU']==0)]\n","    print('[FALSE POSITIVES] Total : {} | Real : {}'.format(len(fp),len(real_fp)))\n","    print('---')\n","    print('')\n","\n","    # Save confusion matrix\n","    outpath = os.path.join(models[model_name]['out'],f'{flight}_{model_name}_{seed}_cm.csv')\n","    perfs.confusion_matrix.to_csv(outpath)\n","\n","    # Save comparison file\n","    outpath = os.path.join(models[model_name]['out'],f'{flight}_{model_name}_{seed}_compare.csv')\n","    perfs.compare.to_csv(outpath, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_-Yw4DCm3a-1"},"source":["## 3) Extract False Positives with IoU = 0\n","You will have to run the cells below **for each flight**, without forgetting to modify the information contained in the variables of the first cell.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VhwyvKsK8sxq"},"source":["### To fill for each run"]},{"cell_type":"code","metadata":{"id":"PQ1BeKyE6APF"},"source":["flight_name = 'ENTER THE FLIGHT NAME'\n","images_folder = '< path to one Garamba UAV flight folder >'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dI3JjVtM8xPQ"},"source":["### Extract FPs patches"]},{"cell_type":"code","metadata":{"id":"5nUfG4g33t67"},"source":["import os\r\n","from PIL import Image\r\n","import pandas as pd\r\n","\r\n","outpath = models[model_name]['out']\r\n","buffer = 15 # Buffer in pixels around the animal\r\n","preds =  pd.read_csv(os.path.join(models[model_name]['out'],f'{flight_name}_{model_name}_{seed}_compare.csv'))\r\n","\r\n","# Get only FP with IoU = 0\r\n","preds_filter = preds[(preds['Assignment']=='FP')&(preds['IoU']==0)]\r\n","preds_filter = preds_filter.reset_index(drop=True)\r\n","# Cut FP bounding boxes with buffer and save\r\n","save_path = os.path.join(outpath, flight_name, 'FP')\r\n","\r\n","if os.path.exists(save_path) is not True:\r\n","    os.makedirs(save_path)\r\n","\r\n","for i , p in preds_filter.iterrows():\r\n","    # Open image\r\n","    img = Image.open(os.path.join(images_folder,p.Image))\r\n","\r\n","    # Crop\r\n","    box = [p.x1 - buffer, p.y1 - buffer,\r\n","        p.x2 + buffer, p.y2 + buffer]\r\n","    crop = img.crop(box)\r\n","\r\n","    # Save\r\n","    s = round(p.Score,2) # score\r\n","    l = int(p.Label) # label = species id\r\n","\r\n","    if i==0:\r\n","        j = 1 # image individual id\r\n","    else:\r\n","        if preds_filter.at[i-1,'Image']==p.Image:\r\n","            j += 1\r\n","        else:\r\n","            j = 1\r\n","\r\n","    save_name = os.path.join(save_path,\r\n","        p.Image[:-4] + '_' + str(l) + '_n_' + str(j) + '_s_' + str(s)+ '.JPG')\r\n","\r\n","    crop.save(save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TmcTK3-F8TSi"},"source":["### Plot FPs in context\n","Plot the FPs on entire image to have surrounding context for decision-making."]},{"cell_type":"code","metadata":{"id":"XWCTR9o08rAo"},"source":["import os\r\n","from PIL import Image, ImageDraw\r\n","\r\n","# Make a new folder\r\n","save_path = os.path.join(outpath, flight_name, 'FP_in_context')\r\n","\r\n","if os.path.exists(save_path) is not True:\r\n","    os.makedirs(save_path)\r\n","\r\n","for i in list(set(preds_filter['Image'])):\r\n","    # Open image\r\n","    img_path = os.path.join(images_folder,i)\r\n","\r\n","    det = preds_filter[preds_filter['Image']==i].values.tolist()\r\n","    \r\n","    savepath = os.path.join(save_path,i)\r\n","\r\n","    # Plot detections on the image\r\n","    with Image.open(img_path) as img:\r\n","        draw = ImageDraw.Draw(img)\r\n","\r\n","        for d in det:\r\n","            draw.rectangle(d[1:5],outline='red',width=2)\r\n","\r\n","        img.save(savepath,\"JPEG\",quality=95)"],"execution_count":null,"outputs":[]}]}